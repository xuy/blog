---
id: 1052
title: 编程珠玑番外篇-I. 高级语言是怎么来的-5
date: 2010-02-10T21:15:05+00:00
author: Eric
comments: true
layout: post
guid: http://blog.youxu.info/?p=1052
permalink: /2010/02/10/lisp-and-ai-2/
dsq_thread_id:
  - 337386028
categories:
  - AI
  - CompSci
  - pearl
---
#### LISP 语言是怎么来的–LISP 和 AI 的青梅竹马 B

上回我们说到 LISP 和 AI 很是青梅竹马的时候，浮光掠影地说因为 LISP 的基本数据单元&#8211;&#8220;链表&#8221;在知识表示上的比较优势。 我们说， AI 要处理的数据结构和要刻画的现实世界的模型很复杂，使得数组等其他简单数据结构不能胜任，所以“链表”成了最佳的选择。 如果我们顺着这样的逻辑线往下看，似乎选择 LISP 这个“列表处理的语言”似乎是理所当然的。 可是，这个原因并不充分。 因为 LISP 语言可不仅仅是列表处理，还包括函数式编程等等其他。 反过来说，如果仅仅是列表处理对于 AI 至关重要的话，那么在 FORTRAN 和 Algol 这些通用编程语言又非常普及的传统语言里面写一些关于列表处理的函数岂不是更加直观和方便？ 归根结底，到底 LISP 还有什么其他奥妙呢？

当我们追寻函数式编程这条线索的时候，就会不可避免的触及到 AI 的早期历史。LISP 的特性，其实都是和当时 AI 的范式 (paradigm) 息息相关的。

**AI 范式的演变**

早在 McCarthy 这一代人提出 AI 之前，冯诺伊曼等人就开始研究什么是智能以及如何实现智能的问题了。 所不同的是，他们更加偏重于研究大脑的内部工作机理，并且试图通过在模拟大脑的工作机理，来实现智能。 这一学派的哲学很清晰： 人类大脑是一个标准的智能体，我们只需要让计算机模拟人的大脑的工作方式，计算机就有了和人类大脑一样的智能了。 对于这一派的研究者来说，他们相信大脑的结构和工作机理决定了智能，至于大脑是用脑细胞构成的，还是用电子电路模拟的，对于智能来说毫不重要。 这方面的著名工作就是冯诺伊曼的《计算机和大脑》这篇论文。 在这篇不算很学术的随笔里面，他分析了人的大脑有多少个神经元，计算机有多少个晶体管，通过这些定量的比较来解释计算机和人的大脑的差距。 当时和冯诺伊曼齐名的另一个神童是开创控制论的维纳。 他和冯诺伊曼一样，兼通很多学科。 和冯诺伊曼一样，他职业是数学家，但是也精通如神经科学和脑科学等学科。一个显然的例子就是在《控制论》这本书里面， 维纳对大脑和神经的分析比比皆是。这种对大脑和神经分析的传统，从 Cajal (对，就是写 <span class="citation book">Advice for a Young Investigator 的那个大神) </span>开始，一直延续到了后来 AI 中的联接主义(主要研究神经网络的一个人工智能学派)。

可是，从脑科学和认知科学的角度去分析智能在当时有一个非常大的局限: 脑神经解剖学本身不成熟。 比方说，现如今脑科学家在分析脑功能的时候一般会借助于 fMRI 和其他一些神经造影技术。这些技术可以做到实时观测到脑中血氧分布，直接确定大脑在执行特定任务时候的活跃部分。当年的科学家则只能使用有限的几种医学成像技术，或者从血管摄影的角度研究大脑。 受限于当时的研究条件，当年的研究者很难直接观测到脑神经的实时工作状态，分析大脑的实时工作机理。 因此，对脑的研究就很难做到非常深刻。 医学研究条件的限制，加上当时电子学的发展和集成度远远不够，用电子电路模拟大脑生成智能就显得非常遥远。 因此，虽然这一派的思想超前，但是大部分的工作都不在于真正的用电子电路模拟大脑，而是在探索脑科学和神经科学本身，或者仅仅用电子电路模拟一些简单的神经动力学行为和小规模神经网络。正是因为连接主义在实现人工智能本身方面进展并不大，所以在AI领域中一直不是潮流的研究方向。上个世纪 80 年代前成功实施的一些人工智能系统，极少是来自于连接主义学派的。直到80年代后随着 BP 算法的重新发现，联接主义才迎来了第二春。 这时候，LISP 已经过完 20 岁生日了。所以，联接主义 对 AI 领域使用的编程语言的选择的影响并不算大。

**符号主义**

虽然联接主义这一学派在当时不怎么流行，当年的 AI 研究可是进行的如火如荼。这如火如荼的学派，采用的是另外一套方法，我们称之为“符号主义学派”。 符号主义学派的渊源，可以直接追溯到图灵。图灵在人工智能方面做过很多的研究，其中最为大家所知的就是“图灵测试“了。 有句俗话叫做“在网上，没人知道你是一条狗”， 在这句话里，只要把“狗”换成“计算机”，就是简单版的图灵测试了。 用个比较“潮”的比方，图灵测试就是让一台计算机或者一个真实的人（又叫评委）在网上交流，然后让这个评委猜测和他交谈的究竟是人还是计算机。 如果这位评委也不能分辨谈话的对方到底是人还是计算机的话，我们就认为这个计算机已经足以“以假乱真”，拥有“和人类一样的智能”了，也就是通过“图灵测试了”。

在很长一段时间里，图灵测试一直是人工智能研究的圣杯(holy grail)。 也就是说，通过”图灵测试“ 成了人工智能研究的终极目标。 那么，自然的，最最直接的通过图灵测试的方法不是让计算机和人脑一样思考，而是只要能够让计算机处理对话中用到的的单词，句子和符号，并且在对话中能够和人一样的操纵这些单词和符号，计算机就有很大的希望通过图灵测试。 从最极端的情况来看，计算机甚至都不需要去“理解”这些句子的含义，都有可能通过图灵测试。 [具体细节可以阅读 Wikipedia 上的“[Chinese Room](http://en.wikipedia.org/wiki/Chinese_room) (中文房间)”条目]。 有一个开源的聊天机器人，叫做 A.L.I.C.E.， 就把上面我们说的“只要能够处理和操纵符号，就有可能通过图灵测试”发挥到了近乎极致。 这个聊天机器人在图灵测试比赛中已经多次骗过人类评委，到了非常“智能”几乎能以假乱真的地步。可是，就是这样一个离通过图灵测试很近的机器人，其基本结构却简单到了我们都不能想像的地步：A.L.I.C.E.  的数据库里面有一条一条的规则，这些规则规定了她看到你说什么的时候她说什么。唯一有点“智能”的地方，就是有些规则不光取决于你这句话，还取决于你的上一句话。 [比如日常对话中我们先问“你喜欢看电影么？”，接着再问“什么类型的？”，这时候就需要前一句话推出这个问题是“（喜欢）什么类型的（电影)”]。“中文房间”的例子，和 A.L.I.C.E. 机器人如此简单的结构，都出人意料的显示出，即使计算机拥有了对符号的操作能力，通过了图灵测试，它也未必是是“有智能”的。 可惜这句话只是我的马后炮而已，在 AI 发展的早期，因为图灵测试的拉动，联接主义的相对弱势和符号主义的繁盛，都把全世界的 AI 研究往一个方向拽，这个方向，很自然的，就是“符号处理”。

**符号处理和 LISP 补充**

其实上一篇我们已经提到了，Alan Newell 和 Herbert Simon 认为对符号演算系统就可以衍生出智能，所以上面的文字，算是对符号主义这个 paradigm 做一个历史的小注解。 当我们把 LISP 放到这段历史中，就会自然的想到， 什么语言适合人工智能的问题，就变成了“什么语言能做符号处理”。这个问题的答案，读者也都猜到了，就是 LISP。

符号处理在 LISP 里面的长处前文我已经介绍过一些了，这里我们可以再补充几点零碎的。LISP 里有一个大家都知道的统一表示程序和数据的方法，叫做 S-Expression。 这个 S，其实就是 Symbolic 的意思。 把程序和数据都统一的当成符号，用现代编程语言的话说，就是 LISP 支持 meta-programming。LISP 程序可以处理，生成和修改 LISP 程序。这个特性，加上函数是一阶对象的特性，使得 LISP 远远比同时代的任何语言灵活。我本人不是 LISP 的用户（初级用户都算不上），因此在这一点上所知有限。但单就我有限的对 LISP 的理解，我认为 LISP 的这种灵活，恰好满足了基于符号处理的 AI 领域对语言的“强大的表达能力”（可以对任何复杂系统建模）和“高层的抽象能力” 的需求。关于第一点，有一个著名的段子，说任何一门编程语言技巧和思想被提出的时候，总会有一个高人出来，说，这个玩意儿在 LISP 里面早就有了，具体的例子包括刚才说的 metaprogramming, object oriented language。这里面蕴含的，就是 LISP 的强大的表达能力，使得很多编程的范式，在 LISP 里面都能实现，或者找到影子。 关于第二点，SICP 中例子比比皆是，讲得都比我深刻许多，就无需废话了。

在上篇文章中我提到，翻开任何一本编程的书，都会讲到“LISP是适合 AI 的编程语言”。那么，如果您和我当年一样，有兴趣从事 AI 方面的研究和探索，就不免要疑惑：“为了学习 AI， 我要不要学习 LISP” 呢？现在距离我当年的这个疑惑已经差不多8年了，我并没有一个确定的答案，但是我知道了更多的一些事实。

**如今的 AI 范式**

如果你让任何一个 AI 方向的研究者推荐几本适合初学者的书的话，十有八九他会提到 &#8220;Artificial Intelligence: A Modern Approach&#8221;(人工智能，一种现代方法) 和 &#8220;Artificial Intelligence: A New Synthesis&#8221; (人工智能，一个新的综述)。 这两本书的作者分别是 Peter Norvig 和 Nils Nilsson，都是 AI 领域的元老级人物。 如果你是一个对书名很敏感的人，你肯定会想：奇怪了，这种书又不是畅销书，难道这两位大牛写了书怕卖不出去，非要在书名上加一个 &#8220;现代&#8221; 或者 “新” 来吸引眼球？ 事实上，这个“现代”和这个“新”都大有来头。 实际上，这二十年来，AI 研究领域接连发生了好几个非常大的 paradigm shift. 传统的基于符号的 AI 方法不再是主流，取而代之的，是多种多样的基于统计的，基于自动推理的，基于机器学习的，基于群体智慧的，基于大规模数据集的等等各种各样研究方法的兴起。 这个 paradigm shift, 对于领域之外的人好像是静悄悄的，可实际上 AI 领域早已发生了翻天覆地的变化。所以才会有 “新” 和 “现代” 这样的词出现在书标题上。 不幸的是，大多写编程语言书的作者，未必全部知晓这个变化，因此还沿袭原来的框架，继续写下 “LISP是适合 AI 的编程语言” 这样一个早就不能完全反映现状的断言。 如果我们统计一个从事 AI 研究的研究者或者科学家用什么语言，答案可能是五花八门无所不有： 做 AI Search 的用 C/C++/Java, 做机器学习的如果模型和矩阵关系密切，可以用 Matlab, 如果统计计算较多，也可以用 R。 至于做数据挖掘等等，语言和库更加五花八门，根本无法宣称那一个语言占上风。LISP 是适合 AI 的语言的教科书神话，也早就被无数的这样的实例给打破了。

延伸阅读：

<http://stackoverflow.com/questions/130475/why-is-lisp-used-for-ai>